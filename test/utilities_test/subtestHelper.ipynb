{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from programmingalpha.DataSet.DBLoader import MongoWikiDoc,MongodbAuth\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "fmt = logging.Formatter('%(asctime)s: [ %(message)s ]', '%m/%d/%Y %I:%M:%S %p')\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(fmt)\n",
    "logger.addHandler(console)\n",
    "\n",
    "db=MongoWikiDoc(**MongodbAuth)\n",
    "db.useDB('wikidocs')\n",
    "db.setDocCollection('articles')\n",
    "\n",
    "#text=db.get_doc_text(18585770)\n",
    "#print(text)\n",
    "#exit(10)\n",
    "\n",
    "def requestData(id=None):\n",
    "    S=requests.Session()\n",
    "    url=\"https://en.wikipedia.org/w/api.php\"\n",
    "    params={\n",
    "        \"action\":\"query\",\n",
    "        \"format\":\"json\",\n",
    "        \"pageids\":id,\n",
    "        #\"titles\":\"Gradient descent\",\n",
    "        \"prop\":\"categories\"\n",
    "    }\n",
    "\n",
    "    R=S.get(url=url,params=params)\n",
    "\n",
    "    data=R.json()\n",
    "    #print(data)\n",
    "    data=data[\"query\"][\"pages\"][str(id)]\n",
    "    cats=[]\n",
    "    for cat in data[\"categories\"]:\n",
    "        #print(cat)\n",
    "        cats.append(cat[\"title\"][9:])\n",
    "\n",
    "    return {\"Id\":id,\"Title\":data[\"title\"],\"categories\":cats}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init with 5548227 doc ids\n"
     ]
    }
   ],
   "source": [
    "wikidoc_ids=db.get_doc_ids()\n",
    "print(\"init with {} doc ids\".format(len(wikidoc_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网站反爬虫：一个IP频繁访问就先将该IP加入黑名单\n",
    "#反爬虫策略：限制IP访问频率，超过频率就自动断开：降低爬虫的速度，在每个请求前加time.sleep,或更换IP\n",
    "#策略二：后台对访问进行统计，如果单个userAgent访问超过阈值，予以封锁：误伤较大，一般网站不使用\n",
    "#策略三：针对cookies：一般网站不使用\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "#首先，我们找一个发布代理IP的网站，从该网站爬取代理IP来访问网页，当本地IP失效，启用代理IP\n",
    "\n",
    "class download(object):\n",
    "    def __init__(self):\n",
    "        self.ip_list=[]   #初始化列表用来存储获取到的IP\n",
    "        html=requests.get(\"http://haoip.cc/tiqu.htm\")\n",
    "        iplistn=re.findall(r'r/>(.*?)<b',html.text,re.S)   #从html代码中获取所有/><b中的内容 re.S的意思是匹配包括所有换行符\n",
    "        for ip in iplistn:\n",
    "            i=re.sub(\"\\n\",\"\",ip)    #re.sub是re模块替换的方法，这表示将\\n替换为空\n",
    "            self.ip_list.append(i.strip())   #将IP添加到初始化列表中\n",
    "\n",
    "        self.user_agent_list=[\n",
    "            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
    "            \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n",
    "            \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"\n",
    "        ]\n",
    "    def get(self,url,timeout,params=None,proxy=None,num_retries=6):\n",
    "        ua=random.choice(self.user_agent_list)   #从user_agent_list中随机抽取出一个字符串\n",
    "        # print(ua)\n",
    "        header={\"User-Agent\":ua}  #构造一个完整的User_Agent\n",
    "\n",
    "        if proxy==None:    #当代理为空时，不使用代理获取response\n",
    "            try:\n",
    "                response=requests.get(url,params=params,headers=header,timeout=timeout)\n",
    "                return response\n",
    "            except:\n",
    "                if num_retries>0:\n",
    "                    time.sleep(10)\n",
    "                    print(u\"获取网页错误，10s后将获取倒数第：\",num_retries,u\"次\")\n",
    "                    return self.get(url,timeout,params,num_retries-1)  #调用自身并将次数减1\n",
    "                else:\n",
    "                    print(u\"开始使用代理\")\n",
    "                    time.sleep(10)\n",
    "                    IP=\"\".join(str(random.choice(self.ip_list)).strip())\n",
    "                    proxy={\"http\":IP}\n",
    "                    return self.get(url,timeout,proxy)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                IP=\"\".join(str(random.choice(self.ip_list)).strip())   #随机取IP并去除空格\n",
    "                proxy={\"http\":IP}   #构造一个代理\n",
    "                response=requests.get(url,headers=header,params=params,proxies=proxy,timeout=timeout)  #使用代理来获取response\n",
    "                return response\n",
    "            except:\n",
    "                if num_retries>0:\n",
    "                    time.sleep(10)\n",
    "                    IP=\"\".join(str(random.choice(self.ip_list)).strip())\n",
    "                    print(u\"正在更换代理，10s后将重新获取第\",num_retries,u\"次\")\n",
    "                    print(u\"当前代理是：\",proxy)\n",
    "                    return self.get(url,timeout,proxy,num_retries-1)\n",
    "                else:\n",
    "                    print(u\"代理发生错误，取消代理\")\n",
    "                    return self.get(url,3)\n",
    "\n",
    "request=download();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
